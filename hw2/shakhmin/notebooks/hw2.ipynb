{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel, PipelineStage}\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.classification.{LogisticRegression, LogisticRegressionModel,\n",
    "                                           RandomForestClassifier}\n",
    "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder, CrossValidatorModel}\n",
    "import org.apache.spark.ml.feature.{VectorAssembler, Imputer, OneHotEncoderEstimator, \n",
    "                                    StringIndexer, StandardScaler}\n",
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "import org.apache.spark.sql.functions.{sum, col, round, regexp_extract, lit, _}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.types.IntegerType\n",
    "import org.apache.spark.sql.SaveMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainDf = [PassengerId: int, Survived: int ... 10 more fields]\n",
       "testDf = [PassengerId: int, Pclass: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Pclass: int ... 9 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainDf = spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"../data/train.csv\")\n",
    "val testDf = spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viewMisData: (df: org.apache.spark.sql.DataFrame)Unit\n",
       "viewDf: (df: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def viewMisData(df:DataFrame) {\n",
    "    println(\"Missing data:\")\n",
    "    df.select(df.columns.map(c => sum(col(c).isNull.cast(\"int\")).alias(c)): _*).show()\n",
    "}\n",
    "\n",
    "def viewDf(df:DataFrame) {\n",
    "    println(\"Size = \" + df.count)\n",
    "    df.printSchema()\n",
    "    df.show()\n",
    "    viewMisData(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим два _dataframe_ для дальнейшей обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size = 1309\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Missing data:\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|     418|     0|   0|  0|263|    0|    0|     0|   1| 1014|       2|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = trainDf.union(testDf.withColumn(\"Survived\", lit(null: String))\n",
    "                     .select(trainDf.columns.head, trainDf.columns.tail: _*))\n",
    "viewDf(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в выборке имеются пропущенные данные, причем признака _Cabin_ существенно не хватает, поэтому в дальнейшем иключим его из выборок. Признак _Fare_ являются числовым, и пропущенных значений в этом столбце немного, поэтому их можно заменить, например, на среднее значение. Признак _Embarked_ строковый, и поскольку пропущенных значений немного, то заполним их часто встречающимся значением. Признак _Age_ является числовым, но замена пропущенных значений на среднее значение здесь не подойдет, его обработку рассмотрим в дальнейшем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заполенение пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "processedDf = [PassengerId: int, Survived: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 9 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var processedDf = df.drop(\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mostEmbarked = S\n",
       "processedDf = [PassengerId: int, Survived: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 9 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mostEmbarked = df.groupBy(\"Embarked\")\n",
    "                     .count()\n",
    "                     .orderBy(desc(\"count\"))\n",
    "                     .first()\n",
    "                     .getAs[String](0)\n",
    "processedDf = processedDf.na.fill(mostEmbarked, Seq(\"Embarked\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fareImputer = imputer_227fa927b11f\n",
       "processedDf = [PassengerId: int, Survived: int ... 9 more fields]\n",
       "processedDf = [PassengerId: int, Survived: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 9 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fareImputer = new Imputer()\n",
    "  .setInputCols(Array(\"Fare\"))\n",
    "  .setOutputCols(Array(\"Fare\"))\n",
    "  .setStrategy(\"mean\")\n",
    "processedDf = fareImputer.fit(processedDf).transform(processedDf)\n",
    "processedDf = processedDf.withColumn(\"Fare\", round(col(\"Fare\"), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data:\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+--------+\n",
      "|          0|     418|     0|   0|  0|263|    0|    0|     0|   0|       0|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "viewMisData(processedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что в поле имя присустсвует аббревиатура (_Mr_ , _Miss_ и т.д.), которая может помочь заполнить пропущенные значения в столбце _Age_. Но данные значения нужно нормализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|   Title|\n",
      "+--------+\n",
      "|    Dona|\n",
      "|     Don|\n",
      "|    Miss|\n",
      "|Countess|\n",
      "|     Col|\n",
      "|     Rev|\n",
      "|    Lady|\n",
      "|  Master|\n",
      "|     Mme|\n",
      "|    Capt|\n",
      "|      Mr|\n",
      "|      Dr|\n",
      "|     Mrs|\n",
      "|     Sir|\n",
      "|Jonkheer|\n",
      "|    Mlle|\n",
      "|   Major|\n",
      "|      Ms|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "processedDf = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedDf = processedDf.withColumn(\"Title\",regexp_extract($\"Name\",\"([A-Za-z]+)\\\\.\",1))\n",
    "processedDf.select(\"Title\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  Title|\n",
      "+-------+\n",
      "|   Miss|\n",
      "|Officer|\n",
      "|Royalty|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|    Mrs|\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mapTitle = Map(Master -> Master, Countess -> Royalty, Capt -> Officer, Mr -> Mr, Dr -> Officer, Don -> Royalty, Rev -> Officer, Lady -> Royalty, Mrs -> Mrs, Miss -> Miss, Mlle -> Miss, Major -> Officer, Col -> Officer, Dona -> Royalty, Mme -> Mrs, Sir -> Royalty, Jonkheer -> Royalty, Ms -> Mrs)\n",
       "modifyTitle = > String = <function1>\n",
       "modifyTitleUDF = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n",
       "processedDf = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mapTitle = Map(\"Dona\" -> \"Royalty\", \"Don\" -> \"Royalty\", \n",
    "                   \"Miss\" -> \"Miss\", \"Countess\" -> \"Royalty\", \n",
    "                   \"Col\" -> \"Officer\", \"Rev\" -> \"Officer\", \n",
    "                   \"Lady\"-> \"Royalty\", \"Master\" -> \"Master\", \n",
    "                   \"Mme\" -> \"Mrs\", \"Capt\" -> \"Officer\", \n",
    "                   \"Mr\" -> \"Mr\", \"Dr\" -> \"Officer\", \n",
    "                   \"Mrs\" -> \"Mrs\", \"Sir\" -> \"Royalty\", \n",
    "                   \"Jonkheer\" -> \"Royalty\", \"Mlle\" -> \"Miss\", \n",
    "                   \"Major\" -> \"Officer\", \"Ms\" -> \"Mrs\")\n",
    "val modifyTitle: (String => String) = (oldTitle: String) => mapTitle(oldTitle)\n",
    "val modifyTitleUDF = udf(modifyTitle)\n",
    "\n",
    "processedDf = processedDf.withColumn(\"Title\", modifyTitleUDF($\"Title\"))\n",
    "processedDf.select(\"Title\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map(Officer -> 46.0, Royalty -> 41.0, Mr -> 32.0, Mrs -> 37.0, Miss -> 22.0, Master -> 5.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "titleToAgeMap = Map(Officer -> 46.0, Royalty -> 41.0, Mr -> 32.0, Mrs -> 37.0, Miss -> 22.0, Master -> 5.0)\n",
       "titleToAgeArr = Array([Miss,21.795235849056603], [Officer,46.27272727272727], [Royalty,41.166666666666664], [Master,5.482641509433963], [Mr,32.25215146299484], [Mrs,36.866279069767444])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array([Miss,21.795235849056603], [Officer,46.27272727272727], [Royalty,41.166666666666664], [Master,5.482641509433963], [Mr,32.25215146299484], [Mrs,36.866279069767444])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val titleToAgeMap = scala.collection.mutable.Map[String, Double]()\n",
    "val titleToAgeArr = processedDf.groupBy(\"Title\").avg(\"Age\").collect()\n",
    "for (row <- titleToAgeArr) {\n",
    "    titleToAgeMap += \n",
    "    (row.getAs[String](0) -> \n",
    "     BigDecimal(row.getAs[Double](1)).setScale(0, BigDecimal.RoundingMode.HALF_UP).toDouble)\n",
    "}\n",
    "println(titleToAgeMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data:\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+--------+-----+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Embarked|Title|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+--------+-----+\n",
      "|          0|     418|     0|   0|  0|  0|    0|    0|     0|   0|       0|    0|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+--------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fillAge = > Double = <function1>\n",
       "fillAgeUDF = UserDefinedFunction(<function1>,DoubleType,Some(List(StringType)))\n",
       "processedDf = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fillAge = (title: String) => titleToAgeMap(title)\n",
    "val fillAgeUDF = udf(fillAge)\n",
    "processedDf = processedDf.withColumn(\"Age\", when($\"Age\".isNull, fillAgeUDF($\"Title\")).otherwise($\"Age\"))\n",
    "viewMisData(processedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно на выживаемость влиял и размер семьи у пассажира, поэтому создадим новый признак _FamilySize_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|PassengerId|FamilySize|\n",
      "+-----------+----------+\n",
      "|          1|         2|\n",
      "|          2|         2|\n",
      "|          3|         1|\n",
      "|          4|         2|\n",
      "|          5|         1|\n",
      "|          6|         1|\n",
      "|          7|         1|\n",
      "|          8|         5|\n",
      "|          9|         3|\n",
      "|         10|         2|\n",
      "|         11|         3|\n",
      "|         12|         1|\n",
      "|         13|         1|\n",
      "|         14|         7|\n",
      "|         15|         1|\n",
      "|         16|         1|\n",
      "|         17|         6|\n",
      "|         18|         1|\n",
      "|         19|         2|\n",
      "|         20|         1|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "processedDf = [PassengerId: int, Survived: int ... 11 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 11 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedDf = processedDf.withColumn(\"FamilySize\", $\"SibSp\" + $\"Parch\" + 1)\n",
    "processedDf.select(\"PassengerId\", \"FamilySize\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим _dataframe_ на два исходных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "processedTrainDf = [PassengerId: int, Survived: int ... 11 more fields]\n",
       "processedTestDf = [PassengerId: int, Pclass: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Pclass: int ... 10 more fields]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val processedTrainDf = processedDf.filter($\"Survived\".isNotNull)\n",
    "val processedTestDf = processedDf.filter($\"Survived\".isNull).drop(\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train = [PassengerId: int, Survived: int ... 11 more fields]\n",
       "test = [PassengerId: int, Survived: int ... 11 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 11 more fields]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train, test) = processedTrainDf.randomSplit(Array(0.7, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assemblerForScaling = vecAssembler_25944073dd21\n",
       "scaler = stdScal_c517ae49c4be\n",
       "sexIndexer = strIdx_998b80382d0b\n",
       "embarkedIndexer = strIdx_ec72a2570305\n",
       "titleIndexer = strIdx_f0827ae1cd0d\n",
       "encoder = oneHotEncoder_ed127930034f\n",
       "finalAssembler = vecAssembler_968c12202e0e\n",
       "eval = binEval_e76f79e3ffc0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "preProcessStages: Array[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: or...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "binEval_e76f79e3ffc0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assemblerForScaling = new VectorAssembler()\n",
    "    .setInputCols(Array(\"Age\", \"Fare\", \"Parch\", \"SibSp\", \"FamilySize\"))\n",
    "    .setOutputCol(\"NeedScaling\")\n",
    "\n",
    "val scaler = new StandardScaler()\n",
    "    .setInputCol(\"NeedScaling\")\n",
    "    .setOutputCol(\"ScaledFeatures\")\n",
    "    .setWithStd(true)\n",
    "    .setWithMean(false)\n",
    "\n",
    "val sexIndexer = new StringIndexer()\n",
    "    .setInputCol(\"Sex\")\n",
    "    .setOutputCol(\"SexIndex\")\n",
    "\n",
    "val embarkedIndexer = new StringIndexer()\n",
    "    .setInputCol(\"Embarked\")\n",
    "    .setOutputCol(\"EmbarkedIndex\")\n",
    "\n",
    "val titleIndexer = new StringIndexer()\n",
    "    .setInputCol(\"Title\")\n",
    "    .setOutputCol(\"TitleIndex\")\n",
    "\n",
    "val encoder = new OneHotEncoderEstimator()\n",
    "    .setInputCols(Array(\"Pclass\", \"SexIndex\", \"EmbarkedIndex\", \"TitleIndex\"))\n",
    "    .setOutputCols(Array(\"PclassOHE\", \"SexOHE\", \"EmbarkedOHE\", \"TitleIndexOHE\"))\n",
    "    .setHandleInvalid(\"keep\")\n",
    "\n",
    "val finalAssembler = new VectorAssembler()\n",
    "    .setInputCols(Array(\"ScaledFeatures\", \"PclassOHE\", \"SexOHE\", \"EmbarkedOHE\", \"TitleIndexOHE\"))\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "val eval = new BinaryClassificationEvaluator()\n",
    "    .setLabelCol(\"Survived\")\n",
    "\n",
    "val preProcessStages = Array(assemblerForScaling, scaler, sexIndexer, \n",
    "                             embarkedIndexer, titleIndexer ,encoder, finalAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr = logreg_db629369bdd2\n",
       "lrParamGrid = \n",
       "lrCV = cv_70bee67a6938\n",
       "lrModelCV = cv_70bee67a6938\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array({\n",
       "\tlogreg_db629369bdd2-regParam: 0.01\n",
       "}, {\n",
       "\tlogreg_db629369bdd2-regParam: 0.005\n",
       "}, {\n",
       "\tlogreg_db629369bdd2-regParam: 0.001\n",
       "}, {\n",
       "\tlogreg_db629369bdd2-regParam: 5.0E-4\n",
       "}, {\n",
       "\tlogreg_db629369bdd2-regParam: 1.0E-4\n",
       "})\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cv_70bee67a6938"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr = new LogisticRegression()\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setLabelCol(\"Survived\")\n",
    "\n",
    "val lrParamGrid = new ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, Array(1e-2, 5e-3, 1e-3, 5e-4, 1e-4))\n",
    "    .build()\n",
    "\n",
    "val lrCV = new CrossValidator()\n",
    "    .setEstimator(new Pipeline().setStages(preProcessStages ++ Array(lr)))\n",
    "    .setEvaluator(eval)\n",
    "    .setEstimatorParamMaps(lrParamGrid)\n",
    "    .setNumFolds(5)\n",
    "\n",
    "val lrModelCV = lrCV.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf = rfc_9e3a9759082c\n",
       "rfParamGrid = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array({\n",
       "\trfc_9e3a9759082c-impurity: gini,\n",
       "\trfc_9e3a9759082c-maxDepth: 1,\n",
       "\trfc_9e3a9759082c-minInstancesPerNode: 1\n",
       "}, {\n",
       "\trfc_9e3a9759082c-impurity: gini,\n",
       "\trfc_9e3a9759082c-maxDepth: 2,\n",
       "\trfc_9e3a9759082c-minInstancesPerNode: 1\n",
       "}, {\n",
       "\trfc_9e3a9759082c-impurity: gini,\n",
       "\trfc_9e3a9759082c-maxDepth: 5,\n",
       "\trfc_9e3a9759082c-minInstancesPerNode: 1\n",
       "}, {\n",
       "\trfc_9e3a9759082c-impurity: gini,\n",
       "\trfc_9e3a9759082c-maxDepth: 10,\n",
       "\trfc_9e3a9759082c-minInstancesPerNode: 1\n",
       "}, {\n",
       "\trfc_9e3a9759082c-impurity: gini,\n",
       "\trfc_9e3a9759082c-maxDepth: 15,\n",
       "\trfc_9e3a9759082c-minInstancesPerNode: 1\n",
       "}, {\n",
       "\trfc_9e3a9759082c-impurity: entropy,\n",
       "\trfc_9e3a9759082c-maxDepth: 1,\n",
       "\trfc_9e3a9759082c-minInsta...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val rf = new RandomForestClassifier()\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setLabelCol(\"Survived\")\n",
    "\n",
    "val rfParamGrid = new ParamGridBuilder()\n",
    "    .addGrid(rf.impurity, Array(\"gini\", \"entropy\"))\n",
    "    .addGrid(rf.maxDepth, Array(1, 2, 5, 10, 15))\n",
    "    .addGrid(rf.minInstancesPerNode, Array(1, 2, 4, 5, 10))\n",
    "    .build()\n",
    "\n",
    "val rfCV = new CrossValidator()\n",
    "    .setEstimator(new Pipeline().setStages(preProcessStages ++ Array(rf)))\n",
    "    .setEvaluator(eval)\n",
    "    .setEstimatorParamMaps(rfParamGrid)\n",
    "    .setNumFolds(5)\n",
    "\n",
    "val rfModelCV = rfCV.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelResults: (model: org.apache.spark.ml.tuning.CrossValidatorModel)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def modelResults(model: CrossValidatorModel) {\n",
    "    println(\"cross-validated areaUnderROC: \" + model.avgMetrics.max)\n",
    "    println(\"test areaUnderROC: \" + eval.evaluate(model.transform(test)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "cross-validated areaUnderROC: 0.857472760941634\n",
      "test areaUnderROC: 0.8839886845827439\n",
      "\n",
      "Random Forest: \n",
      "cross-validated areaUnderROC: 0.8727047995451697\n",
      "test areaUnderROC: 0.8789250353606783\n"
     ]
    }
   ],
   "source": [
    "println(\"Logistic Regression: \")\n",
    "modelResults(lrModelCV)\n",
    "println\n",
    "println(\"Random Forest: \")\n",
    "modelResults(rfModelCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "saveResultForSubmit: (model: org.apache.spark.ml.tuning.CrossValidatorModel, df: org.apache.spark.sql.DataFrame, fileName: String)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def saveResultForSubmit(model: CrossValidatorModel, df: DataFrame, fileName: String) {\n",
    "    val scoredDf = model.transform(processedTestDf)\n",
    "    val outputDf = scoredDf.select(\"PassengerId\", \"prediction\")\n",
    "    val castedDf = outputDf.select(outputDf(\"PassengerId\"), outputDf(\"prediction\").cast(IntegerType).as(\"Survived\"))                                      \n",
    "    castedDf.write.format(\"csv\").option(\"header\", \"true\").save(f\"../data/$fileName%s.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResultForSubmit(lrModelCV, processedTestDf, \"lr\")\n",
    "saveResultForSubmit(rfModelCV, processedTestDf, \"rf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
