val spark = SparkSession.builder().appName("Classifier").config("spark.master", "local").getOrCreate()

   // spark.conf.set("spark.sql.autoBroadcastJoinThreshold", 1024*1024*500)
   // spark.conf.set()



    val dataDF = spark.read.format("csv")
      .option("header", "false")
      .option("delimiter", "\t")
      .load(dataPath)
      .withColumnRenamed("_c0", "cuid")
      .withColumnRenamed("_c1", "cat_feature")
      .withColumnRenamed("_c2", "feature_1")
      .withColumnRenamed("_c3", "feature_2")
      .withColumnRenamed("_c4", "feature_3")
      .withColumnRenamed("_c5", "dt_diff")
      .repartition(10000)


    val testDF = spark.read.format("csv")
      .option("header", "true")
      .option("delimiter", "\t")
      .load(testPath)

    val trainDF = spark.read.format("csv")
      .option("header", "true")
      .option("delimiter", "\t")
      .load(trainPath)
      .join(broadcast(dataDF),Seq("cuid"),"inner")
        .show(6, truncate = false)